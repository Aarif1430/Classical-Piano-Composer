{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/gdl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import note, chord\n",
    "\n",
    "from keras.layers import LSTM, Input, Dropout, Dense, Activation, Embedding, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from utils import get_distinct, create_lookups, prepare_sequences, get_music_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 files in total\n",
      "1 Parsing midi_songs/cs1-2all.mid\n",
      "2 Parsing midi_songs/cs5-1pre.mid\n",
      "3 Parsing midi_songs/cs4-1pre.mid\n",
      "4 Parsing midi_songs/cs3-5bou.mid\n",
      "5 Parsing midi_songs/cs1-4sar.mid\n",
      "6 Parsing midi_songs/cs2-5men.mid\n",
      "7 Parsing midi_songs/cs3-3cou.mid\n",
      "8 Parsing midi_songs/cs2-3cou.mid\n",
      "9 Parsing midi_songs/cs1-6gig.mid\n",
      "10 Parsing midi_songs/cs6-4sar.mid\n",
      "11 Parsing midi_songs/cs4-5bou.mid\n",
      "12 Parsing midi_songs/cs4-3cou.mid\n",
      "13 Parsing midi_songs/cs5-3cou.mid\n",
      "14 Parsing midi_songs/cs6-5gav.mid\n",
      "15 Parsing midi_songs/cs6-6gig.mid\n",
      "16 Parsing midi_songs/cs2-1pre.mid\n",
      "17 Parsing midi_songs/cs3-1pre.mid\n",
      "18 Parsing midi_songs/cs3-6gig.mid\n",
      "19 Parsing midi_songs/cs2-6gig.mid\n",
      "20 Parsing midi_songs/cs2-4sar.mid\n",
      "21 Parsing midi_songs/cs3-4sar.mid\n",
      "22 Parsing midi_songs/cs1-5men.mid\n",
      "23 Parsing midi_songs/cs1-3cou.mid\n",
      "24 Parsing midi_songs/cs6-1pre.mid\n",
      "25 Parsing midi_songs/cs2-2all.mid\n",
      "26 Parsing midi_songs/cs3-2all.mid\n",
      "27 Parsing midi_songs/cs1-1pre.mid\n",
      "28 Parsing midi_songs/cs5-2all.mid\n",
      "29 Parsing midi_songs/cs4-2all.mid\n",
      "30 Parsing midi_songs/cs5-5gav.mid\n",
      "31 Parsing midi_songs/cs4-6gig.mid\n",
      "32 Parsing midi_songs/cs5-6gig.mid\n",
      "33 Parsing midi_songs/cs5-4sar.mid\n",
      "34 Parsing midi_songs/cs4-4sar.mid\n",
      "35 Parsing midi_songs/cs6-3cou.mid\n"
     ]
    }
   ],
   "source": [
    "music_type = 'local'\n",
    "mode = 'build'\n",
    "\n",
    "if mode == 'build':\n",
    "    music_list, parser = get_music_list(music_type)\n",
    "    print(len(music_list), 'files in total')\n",
    "\n",
    "    notes = []\n",
    "    durations = []\n",
    "\n",
    "    for i, file in enumerate(music_list):\n",
    "        print(i+1, \"Parsing %s\" % file)\n",
    "        original_score = parser.parse(file).chordify()\n",
    "        intervals = range(-6,5,1)\n",
    "\n",
    "        for interval in intervals:\n",
    "\n",
    "            score = original_score.transpose(interval)\n",
    "\n",
    "            notes.append('START')\n",
    "            durations.append(0)\n",
    "\n",
    "            for element in score.flat:\n",
    "                \n",
    "                if isinstance(element, note.Note):\n",
    "                    if element.isRest:\n",
    "                        notes.append(str(element.name))\n",
    "                        durations.append(element.duration.quarterLength)\n",
    "                    else:\n",
    "                        notes.append(str(element.nameWithOctave))\n",
    "                        durations.append(element.duration.quarterLength)\n",
    "\n",
    "                if isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(n.nameWithOctave for n in element.pitches))\n",
    "                    durations.append(element.duration.quarterLength)\n",
    "\n",
    "            notes.append('END')\n",
    "            durations.append(0)\n",
    "\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "            pickle.dump(notes, filepath) #['G2', 'D3', 'B3', 'A3', 'B3', 'D3', 'B3', 'D3', 'G2',...]\n",
    "    with open('data/durations', 'wb') as filepath:\n",
    "        pickle.dump(durations, filepath) \n",
    "else:\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath) #['G2', 'D3', 'B3', 'A3', 'B3', 'D3', 'B3', 'D3', 'G2',...]\n",
    "    with open('data/durations', 'rb') as filepath:\n",
    "        durations = pickle.load(filepath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distinct sets of notes and durations\n",
    "note_names, n_notes = get_distinct(notes)\n",
    "duration_names, n_durations = get_distinct(durations)\n",
    "distincts = [note_names, n_notes, duration_names, n_durations]\n",
    "\n",
    "with open('data/distincts', 'wb') as filepath:\n",
    "    pickle.dump(distincts, filepath)\n",
    "\n",
    "# make the lookup dictionaries for notes and dictionaries and save\n",
    "note_to_int, int_to_note = create_lookups(note_names)\n",
    "duration_to_int, int_to_duration = create_lookups(duration_names)\n",
    "lookups = [note_to_int, int_to_note, duration_to_int, int_to_duration]\n",
    "\n",
    "with open('data/lookups', 'wb') as filepath:\n",
    "    pickle.dump(lookups, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the sequences used by the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input, network_output = prepare_sequences(notes, durations, lookups, distincts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the structure of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 100)    185200      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, None, 100)    1800        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, 200)    0           embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, None, 256)    467968      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 256)    0           lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 256)          525312      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256)          0           lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "notes (Dense)                   (None, 1852)         475964      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "durations (Dense)               (None, 18)           4626        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,660,870\n",
      "Trainable params: 1,660,870\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_len = None\n",
    "embed_size = 100\n",
    "\n",
    "notes_in = Input(shape = (seq_len,))\n",
    "durations_in = Input(shape = (seq_len,))\n",
    "\n",
    "x1 = Embedding(n_notes, embed_size)(notes_in)\n",
    "x2 = Embedding(n_durations, embed_size)(durations_in) \n",
    "\n",
    "x = Concatenate()([x1,x2])\n",
    "\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(256)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "notes_out = Dense(n_notes, activation = 'softmax', name = 'notes')(x)\n",
    "durations_out = Dense(n_durations, activation = 'softmax', name = 'durations')(x)\n",
    "\n",
    "model = Model([notes_in, durations_in], [notes_out, durations_out])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opti = RMSprop(lr = 0.001)\n",
    "model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy']\n",
    "              , loss_weights = [5, 1]\n",
    "              , optimizer=opti\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 237160 samples, validate on 59291 samples\n",
      "Epoch 1/2000000\n",
      " 13728/237160 [>.............................] - ETA: 15:11 - loss: 20.9598 - notes_loss: 4.0167 - durations_loss: 0.8765"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    \"./weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.h5\",\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    \"weights.h5\",\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss'\n",
    "    , restore_best_weights=True\n",
    "    , patience = 10\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint1\n",
    "    , checkpoint2\n",
    "    , early_stopping\n",
    " ]\n",
    "\n",
    "model.save_weights('./weights/weights.h5')\n",
    "model.fit(network_input, network_output\n",
    "          , epochs=2000000, batch_size=32\n",
    "          , validation_split = 0.2\n",
    "          , callbacks=callbacks_list\n",
    "          , shuffle=True\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
